<head><title>Subreddit Tone Analysis</title></head>

	<header>
		<a href= "/"><h2>Zach Holsinger</h2></a>
	</header>

<h3>Subreddit Tone Analysis</h3>

<p><b>Commentary:</b><br>    The following is an academic project done in my Computational Semantics class at UT Austin. The goal of this project was to demonstrate computational linguistic skills, so, in my opinion, my thesis was weak and vague. All the mathematics and programming is solid.<p>

<p><b>Report Text:</b><br>    I want to find if it is possible to computationally sort subreddits by their discussion tone or mood, rather than by topic.<br>To do this, I had to get a lot of data from reddit. This was a lengthy, but easy process. Reddit has a fantastic API, and a number of user made libraries allow easier access to it. I used PRAW, Python Reddit Api Wrapper. It converted to python and it automatically dealt with the rate limiting. I systematically scraped twenty subreddits for current hot posts and downloaded their comments. In the end, I was left with 20 .txt files ranging from just under a megabyte to only 15 kb, depending on the brevity of the subreddit. In all, from each subreddit I scraped about two hundred thousand words from each. This data was spread over a variety of subreddits chosen based on my own knowledge of the site.<br>Before any analysis could be done, I had to extensively preprocess the data. Reddit uses mostly informal writing, which is rich in non-text like emojis, links, etc. I removed errata, removed stops and lemmatized the texts before they could be analyzed. This all cut the data down by about a third. <div class="right"> <img alt="image of clusters" src="/clusters.png"  width="251" height="223"><br>I started my analysis using a simple word frequency test. I expected to find mostly topical words, but I also hoped to find some discussion type ones further down in the frequency chart. Next, for a more complex analysis, I did a TF-IDF vectorization. My reasoning was that tone would be represented by a pattern of words used to facilitate longer and more reasoned discussion. This vectorization was then fit to the data, then reduced dimensionally using LSA. Once the numbers had been found, I plotted them on a simple chart. <br> The results were inconclusive. The subreddits formed into two strong groupings that I was unable to determine the cause of.  Post-plotting analysis to determine the cluster causes was inconclusive. I tried sentence length, average word length, punctuation and a few other simple tests and was not able to find a satisfying explanation. Even in my own experience the clusters look strange: writingprompts and askhistorians are two of the longest winded subreddits on the site, and they’re lumped in with dankmemes and meirl, two very light meme subreddits. <br> Despite the inconclusive results, I’m satisfied with how the tests were performed. This experiment would have benefitted from a lot more data. The technique I used to get the comments was somewhat suspect: I grabbed using submissions, which sped up the scraping, but meant that all the comments were related to a smaller number of posts.
</p>
